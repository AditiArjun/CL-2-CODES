{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7izWfaHRtfUx"
   },
   "outputs": [],
   "source": [
    "def pagerank(G, alpha=0.85, personalization=None, max_iter=100, tol=1.0e-6, nstart=None, weight='weight', dangling=None):\n",
    "    if len(G) == 0:\n",
    "        return {}\n",
    "\n",
    "    if not G.is_directed():\n",
    "        D = G.to_directed()\n",
    "    else:\n",
    "        D = G\n",
    "\n",
    "    # Create a copy in (right) stochastic form\n",
    "    W = nx.stochastic_graph(D, weight=weight)\n",
    "    N = W.number_of_nodes()\n",
    "\n",
    "    # Choose fixed starting vector if not given\n",
    "    if nstart is None:\n",
    "        x = dict.fromkeys(W, 1.0 / N)\n",
    "    else:\n",
    "        # Normalized nstart vector\n",
    "        s = float(sum(nstart.values()))\n",
    "        x = dict((k, v / s) for k, v in nstart.items())\n",
    "\n",
    "    if personalization is None:\n",
    "        # Assign uniform personalization vector if not given\n",
    "        p = dict.fromkeys(W, 1.0 / N)\n",
    "    else:\n",
    "        missing = set(G) - set(personalization)\n",
    "        if missing:\n",
    "            raise NetworkXError('Personalization dictionary must have a value for every node. Missing nodes %s' % missing)\n",
    "        s = float(sum(personalization.values()))\n",
    "        p = dict((k, v / s) for k, v in personalization.items())\n",
    "\n",
    "    if dangling is None:\n",
    "        # Use personalization vector if dangling vector not specified\n",
    "        dangling_weights = p\n",
    "    else:\n",
    "        missing = set(G) - set(dangling)\n",
    "        if missing:\n",
    "            raise NetworkXError('Dangling node dictionary must have a value for every node. Missing nodes %s' % missing)\n",
    "        s = float(sum(dangling.values()))\n",
    "        dangling_weights = dict((k, v/s) for k, v in dangling.items())\n",
    "\n",
    "    dangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0]\n",
    "\n",
    "     # power iteration: make up to max_iter iterations\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x\n",
    "        x = dict.fromkeys(xlast.keys(), 0)\n",
    "        danglesum = alpha * sum(xlast[n] for n in dangling_nodes)\n",
    "        for n in x:\n",
    "            # this matrix multiply looks odd because it is\n",
    "            # doing a left multiply x^T=xlast^T*W\n",
    "            for nbr in W[n]:\n",
    "                x[nbr] += alpha * xlast[n] * W[n][nbr][weight]\n",
    "            x[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n]\n",
    "\n",
    "        # check convergence, l1 norm\n",
    "        err = sum([abs(x[n] - xlast[n]) for n in x])\n",
    "        if err < N*tol:\n",
    "            return x\n",
    "    raise NetworkXError('Pagerank: power iteration failed to converge in %d iterations.' % max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4IpjHLg4tstL"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dc1k1Q5Htoyd"
   },
   "outputs": [],
   "source": [
    "G = nx.barabasi_albert_graph(50, 41)\n",
    "pr = nx.pagerank(G, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnUjtCjztuhi",
    "outputId": "11c54bc9-336b-4be6-f3c9-e3ec0c510819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.05445623201833533, 1: 0.01133962021467487, 2: 0.01333168065659518, 3: 0.01333002390995815, 4: 0.0140002041043155, 5: 0.01333463826719248, 6: 0.0140002041043155, 7: 0.0140002041043155, 8: 0.012661500462237832, 9: 0.012668656198159291, 10: 0.012000441443130458, 11: 0.0140002041043155, 12: 0.0140002041043155, 13: 0.013334299478565476, 14: 0.012665776030845158, 15: 0.013334946959883964, 16: 0.01333463826719248, 17: 0.01333168065659518, 18: 0.0140002041043155, 19: 0.0140002041043155, 20: 0.0140002041043155, 21: 0.01333002390995815, 22: 0.012661500462237832, 23: 0.0140002041043155, 24: 0.0140002041043155, 25: 0.0140002041043155, 26: 0.0140002041043155, 27: 0.012000601790499079, 28: 0.013334299478565476, 29: 0.0140002041043155, 30: 0.0140002041043155, 31: 0.01199559583648781, 32: 0.013334946959883964, 33: 0.013336347821979446, 34: 0.0140002041043155, 35: 0.013332048991030562, 36: 0.0140002041043155, 37: 0.0140002041043155, 38: 0.01333002390995815, 39: 0.0140002041043155, 40: 0.012664119284208129, 41: 0.0140002041043155, 42: 0.053454915897191674, 43: 0.05217102664470717, 44: 0.050898003475283046, 45: 0.0498965659939864, 46: 0.048810365630183775, 47: 0.0477252910807598, 48: 0.046798690927666316, 49: 0.04579761936005278}\n"
     ]
    }
   ],
   "source": [
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0xnf-ZctvtC"
   },
   "outputs": [],
   "source": [
    "Aditi Chavan 21259"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
